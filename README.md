# ğŸ¥ Zivian â€” Cloud-Native EHR Data Ingestion Pipeline

> A production-grade, Bronze â†’ Silver â†’ Gold data engineering platform built for Zivian's Elevate Chart Review system. Designed to ingest, transform, and sample patient encounter data from AthenaHealth EHR for supervising physician review.

---

## ğŸ“Œ Project Overview

Zivian required a modern, scalable, and secure data ingestion platform to support their **Elevate** platform â€” a physician chart review system used for regulatory compliance and quality assurance in healthcare.

This project replaces legacy ETL approaches with a **container-first, orchestration-driven architecture** that supports:
- Multi-stage data ingestion (Bronze â†’ Silver â†’ Gold)
- Deterministic 10% encounter sampling for regulatory compliance
- Full auditability and data lineage
- Automated daily pipeline execution

---

## ğŸ—ï¸ Architecture

```
AthenaHealth EHR (Source)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BRONZE LAYER   â”‚  â† Raw NDJSON files (Azure Blob Storage / Local)
â”‚  Immutable,     â”‚    Append-only, exact copy of source data
â”‚  Append-only    â”‚    Directory: /bronze/{tenant}/{env}/{ehr}/{entity}/{timestamp}/
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SILVER LAYER   â”‚  â† PostgreSQL (Staging)
â”‚  Cleaned &      â”‚    Filtered, validated, deduplicated
â”‚  Validated      â”‚    Only completed encounters
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GOLD LAYER    â”‚  â† PostgreSQL (Refined)
â”‚  Business-Ready â”‚    10% deterministic sampling applied
â”‚  + Sampled      â”‚    Flagged for physician chart review
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  Elevate Platform
  (Physician Chart Review)
```

---

## ğŸ”„ Pipeline Stages

### Stage 1 â€” Encounter Extraction (Bronze Layer)
- Simulates AthenaHealth API extraction using OAuth2
- Generates 1,000 patient encounter records
- Stores raw data as **NDJSON** (FHIR standard format)
- Directory structure supports full audit trail and replay

### Stage 2 â€” Data Transformation (Silver Layer)
- Reads raw data from Bronze layer
- Filters only **completed** encounters (removes cancelled/pending)
- Validates schema, enforces data types
- Deduplicates records by `encounter_id`
- Loads **584 clean records** into PostgreSQL Silver table

### Stage 3 â€” Sampling & Gold Layer
- Reads completed encounters from Silver layer
- Applies **deterministic 10% sampling** using MD5 hash of `patient_id`
- Same patients are always selected â€” ensures longitudinal consistency
- Flags **59 encounters** as `is_sampled = TRUE` for chart review
- Loads all records into PostgreSQL Gold table with sampling metadata

---

## ğŸ§  Deterministic Sampling â€” How It Works

```python
def is_sampled(patient_id):
    hash_value = int(hashlib.md5(patient_id.encode()).hexdigest(), 16)
    return hash_value % 10 == 0
```

| Property | Detail |
|----------|--------|
| Method | MD5 Hash % 10 |
| Sample Rate | 10% |
| Consistency | Same patients always selected |
| Auditability | Fully explainable to regulators |
| Replay-safe | No drift on re-runs |

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| Language | Python 3.8+ | Core pipeline logic |
| Orchestration | Apache Airflow 2.8 | DAG scheduling & monitoring |
| Compute | Docker + Docker Compose | Containerized execution |
| Bronze Storage | Local NDJSON / Azure Blob | Raw immutable data store |
| Silver/Gold DB | PostgreSQL 15 | Staging & refined data |
| Data Processing | Pandas + SQLAlchemy | Transform & load |
| Dashboard | Flask + HTML/CSS | Elevate chart review UI |
| CI/CD | GitHub | Version control & deployment |

---

## ğŸ“ Project Structure

```
zivian-project/
â”œâ”€â”€ bronze/                          # Raw data storage (Azure Blob simulation)
â”‚   â””â”€â”€ zivian/dev/athenahealth/
â”‚       â””â”€â”€ encounters/{timestamp}/
â”‚           â””â”€â”€ encounters_raw.ndjson
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ zivian_ingestion_dag.py      # Airflow DAG definition
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â””â”€â”€ extract_encounters.py    # Stage 1: EHR data extraction
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â””â”€â”€ transform_encounters.py  # Stage 2: Silver layer transformation
â”‚   â”œâ”€â”€ sampling/
â”‚   â”‚   â””â”€â”€ sampling_encounters.py   # Stage 3: Gold layer + 10% sampling
â”‚   â”œâ”€â”€ dashboard.py                 # Flask web dashboard
â”‚   â””â”€â”€ chart_viewer.py             # CLI chart review report
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ index.html                   # GitHub Pages dashboard
â”œâ”€â”€ docker-compose.yml               # Full stack container setup
â”œâ”€â”€ Dockerfile                       # Custom Airflow image
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ .env                            # Environment configuration
```

---

## ğŸš€ How to Run

### Prerequisites
- Docker Desktop installed
- Python 3.8+
- PostgreSQL 15+

### Step 1 â€” Clone the Repository
```bash
git clone https://github.com/VENKY-365/zivian-project.git
cd zivian-project
```

### Step 2 â€” Start the Stack
```bash
docker-compose up -d
```

### Step 3 â€” Access Airflow
Open your browser: **http://localhost:8080**
- Username: `admin`
- Password: `admin`

### Step 4 â€” Trigger the Pipeline
- Find `zivian_ingestion_pipeline` DAG
- Click â–¶ to trigger
- Watch Extract â†’ Transform â†’ Sample run automatically!

### Step 5 â€” View the Dashboard
```bash
pip install -r requirements.txt
python services/dashboard.py
```
Open: **http://localhost:5000**

---

## ğŸ“Š Pipeline Results

| Metric | Value |
|--------|-------|
| Raw Encounters Extracted | 1,000 |
| Completed Encounters (Silver) | 584 |
| Cancelled / Pending (Excluded) | 416 |
| Charts Selected for Review (Gold) | 59 |
| Sample Rate | 10% (Deterministic) |
| Pipeline Schedule | Daily at 6:00 AM UTC |

---

## ğŸ” Security & Compliance

- No PHI written to logs or Airflow metadata
- Secrets managed via `.env` file (Azure Key Vault in production)
- Encryption in transit and at rest
- Full audit trail via Bronze layer immutability
- Deterministic sampling ensures regulatory explainability

---

## ğŸŒ Live Dashboard

View the live Elevate Chart Review Dashboard:
**https://venky-365.github.io/zivian-project**

---

## ğŸ“‹ Airflow DAG

```
zivian_ingestion_pipeline
â”‚
â”œâ”€â”€ extract_encounters      (Stage 1 â€” Bronze Layer)
â”‚         â”‚
â”‚         â–¼
â”œâ”€â”€ transform_to_silver     (Stage 2 â€” Silver Layer)
â”‚         â”‚
â”‚         â–¼
â””â”€â”€ sample_to_gold          (Stage 3 â€” Gold Layer)
```

- Schedule: `0 6 * * *` (Every day at 6 AM)
- Retries: 1 (with 2-minute delay)
- Tags: `zivian`, `etl`, `healthcare`

---

## ğŸ‘¨â€ğŸ’» Author

**Venkatesh** â€” Data Engineer
GitHub: [@VENKY-365](https://github.com/VENKY-365)

---

*Built as a POC/Demo for Zivian's Cloud-Native Data Ingestion Platform*
